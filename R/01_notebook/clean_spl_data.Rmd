---
title: "Cleaning the SPL checkouts data"
author: "Leslie Emery"
date: "4/18/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r libraries}
library(dplyr)
```

## 1. Read in the data

If reformatting is needed to read in the data, that will show up in this step. This often comes up with quoted strings (especially if they contain newlines) or unusual missing or comment characters.

```{r read-data}
data_file <- "../../data/spl_checkouts_2020_12.csv"
original <- read.csv(data_file, stringsAsFactors = FALSE)
```


## 2. Validate the data

Check for issues in the data that need to be fixed.

I can already see some potential issues just from looking at the top of the data:

* Some columns of data are in all-caps
* Some values of `title` and `creator` look malformed
* `publicationyear` has some non-digit characters in it

```{r inspect-head}
glimpse(original)
```

The number of rows matches what I expect based on the number of newlines in the file (with `+ 1` accounting for the header row).

```{r expected-rows}
(nrow(original) + 1) == length(readLines(data_file))
```

I expect `publicationyear` to be an integer, but it's a character instead. This is probably because of the non-digit characters I noticed above.

```{r data-types}
sapply(original, typeof)
```

The dataset documentation doesn't include a list of allowed values for each field, so I have to look at the observed values to figure out if there are any invalid values. `usageclass` and `materialtype` values look good, with just a couple of values and no typos. 

Because `checkoutyear` and `checkoutmonth` have a pretty limited set of allowed values, I'm choosing to think of them as categorical variables. The observed values of both match the query parameters that were used to fetch this dataset, so that's great. 

`materialtype` is a bit messy. It's all-caps, which is not wrong, but not how I want it formatted in the end. There are also some records that have multiple values in a comma-separated list. I'll keep the csv format for now, but will want conver to title case or all lowercase later. Some of the values look similar, but without more details in the documentation "VIDEO", "VIDEOCASS", "VIDEODISC", and "VIDEOREC" could very well be different materials.

```{r allowed-values-categorical}
unique(original$usageclass)
unique(original$checkouttype)
unique(original$checkoutyear)
unique(original$checkoutmonth)

unique(original$materialtype)
sort(unique(unlist(strsplit(unique(original$materialtype), ', '))))
```

`publisher`, `subjects`, and `title` are free text. The amount of data cleaning to do here depends on what you're using the data for, and cleaning free text can be very complicated. I'm going to leave these as-is for this example.

```{r allowed-values-free-text}
head(original$publisher)
head(original$subjects)
head(original$title)
```

`checkouts` doesn't have any obvious issues with data values. I'm back to the problem with `publicationdate` now and I can see that there are several kinds of problems to fix:

* Multiple years per row (comma-separated)
* Extraneous text characters including: [].cÂ©?

```{r allowed-values-numeric}
checkout_hist <- hist(original$checkouts)
data.frame(bin_start = checkout_hist$breaks[1:(length(checkout_hist$breaks) - 1)],
           count = checkout_hist$counts)
range(original$checkouts)

head(unique(original$publicationyear), 100)
```

I think this data should be unique for the combination of `checkoutmonth`, `checkoutyear`, `title`, and `creator`. But that turns out to be very wrong! Instead I thought about which fields **should not** be important for record uniqueness. I think that `checkouts` and `subjects` should not be important for record uniqueness.

```{r duplicates}
# Number of duplicates
sum(duplicated(original %>% select(checkoutmonth, checkoutyear, title, creator)))
sum(duplicated(original %>% 
                   select(checkoutmonth, checkoutyear, title, creator,
                          usageclass, checkouttype, materialtype, publisher, publicationyear)))

sum(duplicated(original %>% select(-subjects, -checkouts)))

# Show unexpected duplicates

```


### Invalid data identified

* `publicationyear` should be an integer, but is actually a character, with extraneous formatting around the year date


## 3. Correct the invalid values



## 4. Adjust inconvenient values
